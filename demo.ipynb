{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "t1pBhv0oDsJM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EdcM-wyHrye",
        "outputId": "893873e2-0453-43a0-d0b5-ea73373fb0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from glob import glob\n",
        "from IPython.core.display import clear_output\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare dataset"
      ],
      "metadata": {
        "id": "jdEKXvpTcumo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download dataset from my google disk\n",
        "!unzip \"drive/MyDrive/Colab Notebooks/task_icvr/dataset/dataset.zip\"\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "b7FSkYHdH3ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#You can download dataset by link\n",
        "!gdown \"1BKMXnyPFT6uFWCSbyrZ7r5st9bCQwb2T\"\n",
        "!unzip dataset.zip\n",
        "!rm -rf dataset.zip\n",
        "clear_output()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psd-1zsBCx9L",
        "outputId": "28708dfb-2a99-49ba-b4fe-8817b9128e3f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BKMXnyPFT6uFWCSbyrZ7r5st9bCQwb2T\n",
            "To: /content/dataset.zip\n",
            "100% 3.08G/3.08G [00:23<00:00, 129MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir test\n",
        "!mkdir test/labels\n",
        "!mkdir test/images\n",
        "!mkdir train\n",
        "!mkdir train/labels\n",
        "!mkdir train/images\n",
        "!mkdir valid\n",
        "!mkdir valid/labels\n",
        "!mkdir valid/images"
      ],
      "metadata": {
        "id": "9FLiXyQAZQbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_dataset = len(glob(\"dataset/*.jpg\", recursive=True))\n",
        "for i, root_name in enumerate(glob(\"dataset/*.jpg\", recursive=True)):\n",
        "    if i < len_dataset * 0.8:\n",
        "        shutil.move(root_name, \"train/images\")\n",
        "        shutil.move(root_name[:-3] + \"txt\", \"train/labels\")\n",
        "    elif i < len_dataset * 0.9:\n",
        "        shutil.move(root_name, \"test/images\")\n",
        "        shutil.move(root_name[:-3] + \"txt\", \"test/labels\")        \n",
        "    else:\n",
        "        shutil.move(root_name, \"valid/images\")\n",
        "        shutil.move(root_name[:-3] + \"txt\", \"valid/labels\")\n",
        "!rm -rf dataset"
      ],
      "metadata": {
        "id": "YQ7svakFWiKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Lines = [\"train: ../train/images\\n\",\n",
        "\"val: ../valid/images\\n\", \"\\n\",\n",
        "\"nc: 3\\n\",\n",
        "\"names: ['jacket', 'helmet', 'human']\"]\n",
        "\n",
        "with open('data.yaml', 'w') as writefile:\n",
        "    for line in Lines:\n",
        "        writefile.write(line)\n",
        "        \n",
        "!cat data.yaml"
      ],
      "metadata": {
        "id": "cjRJWLIVsnB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178133bd-3e51-4de4-e859-6228cdddd2d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "\n",
            "nc: 3\n",
            "names: ['jacket', 'helmet', 'human']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train YOLOv5"
      ],
      "metadata": {
        "id": "XF87sIFeczOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd /content/yolov5\n",
        "!pip install -r requirements.txt\n",
        "!pip install \"wandb==0.12.10\""
      ],
      "metadata": {
        "id": "aHWYgwm9uxVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --data ../data.yaml \\\n",
        "  --epochs 15 \\\n",
        "  --project task_icvr \\\n",
        "  --bbox_interval 1 \\\n",
        "  --save-period 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6qpA5N4u_cw",
        "outputId": "3694bee1-640f-40ef-c0b8-88b9ccb573cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=../data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=task_icvr, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.2-194-g2a19d07 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir task_icvr', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m_bro\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.4 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mserene-snowball-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/_bro/task_icvr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/_bro/task_icvr/runs/28hzbycr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolov5/wandb/run-20221014_140835-28hzbycr\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 123MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 277MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/labels' images and labels...2578 found, 0 missing, 121 empty, 0 corrupt: 100% 2578/2578 [00:05<00:00, 496.58it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/valid/labels' images and labels...322 found, 0 missing, 16 empty, 0 corrupt: 100% 322/322 [00:00<00:00, 414.25it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.08 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to task_icvr/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mtask_icvr/exp\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/14      3.74G    0.09689     0.0334    0.02576         21        640: 100% 162/162 [05:20<00:00,  1.98s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:17<00:00,  1.58s/it]\n",
            "                   all        322       2335      0.184      0.344      0.196     0.0609\n",
            "Saving model artifact on epoch 1\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/14      3.74G    0.07412    0.02384    0.02022         18        640: 100% 162/162 [05:08<00:00,  1.90s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.33s/it]\n",
            "                   all        322       2335      0.367      0.526      0.339     0.0836\n",
            "Saving model artifact on epoch 2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/14      3.74G    0.06876    0.02185    0.01857         23        640: 100% 162/162 [05:09<00:00,  1.91s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.30s/it]\n",
            "                   all        322       2335      0.461      0.595      0.539      0.196\n",
            "Saving model artifact on epoch 3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/14      3.74G     0.0635     0.0198    0.01692         31        640: 100% 162/162 [05:04<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.34s/it]\n",
            "                   all        322       2335      0.708      0.746      0.751      0.277\n",
            "Saving model artifact on epoch 4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/14      3.74G    0.05936    0.01908    0.01627          9        640: 100% 162/162 [05:07<00:00,  1.90s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.32s/it]\n",
            "                   all        322       2335      0.692      0.727      0.747      0.307\n",
            "Saving model artifact on epoch 5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/14      3.74G    0.05617     0.0187    0.01558         43        640: 100% 162/162 [05:04<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:16<00:00,  1.53s/it]\n",
            "                   all        322       2335      0.838      0.777      0.842      0.411\n",
            "Saving model artifact on epoch 6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/14      3.74G    0.05365    0.01808    0.01481         10        640: 100% 162/162 [05:02<00:00,  1.87s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.29s/it]\n",
            "                   all        322       2335      0.872      0.776      0.859      0.445\n",
            "Saving model artifact on epoch 7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/14      3.74G    0.05262    0.01763    0.01483          8        640: 100% 162/162 [05:03<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.30s/it]\n",
            "                   all        322       2335      0.876      0.788      0.864      0.428\n",
            "Saving model artifact on epoch 8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/14      3.74G    0.05047    0.01765    0.01423         13        640: 100% 162/162 [05:04<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.29s/it]\n",
            "                   all        322       2335      0.884      0.808      0.882      0.482\n",
            "Saving model artifact on epoch 9\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/14      3.74G    0.04907    0.01675    0.01373         23        640: 100% 162/162 [05:04<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:17<00:00,  1.57s/it]\n",
            "                   all        322       2335      0.873      0.801      0.879       0.48\n",
            "Saving model artifact on epoch 10\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/14      3.74G    0.04813    0.01696    0.01348         13        640: 100% 162/162 [05:07<00:00,  1.90s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.30s/it]\n",
            "                   all        322       2335      0.903      0.792      0.881      0.499\n",
            "Saving model artifact on epoch 11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/14      3.74G    0.04636    0.01625    0.01329         21        640: 100% 162/162 [05:06<00:00,  1.89s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.33s/it]\n",
            "                   all        322       2335      0.881      0.796      0.883       0.51\n",
            "Saving model artifact on epoch 12\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/14      3.74G     0.0456    0.01652    0.01328         15        640: 100% 162/162 [05:04<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.32s/it]\n",
            "                   all        322       2335      0.891      0.801      0.892      0.515\n",
            "Saving model artifact on epoch 13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/14      3.74G    0.04506     0.0162    0.01319         28        640: 100% 162/162 [05:06<00:00,  1.89s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.32s/it]\n",
            "                   all        322       2335      0.894      0.804      0.895      0.528\n",
            "Saving model artifact on epoch 14\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/14      3.74G    0.04438    0.01646    0.01308         21        640: 100% 162/162 [05:04<00:00,  1.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:14<00:00,  1.32s/it]\n",
            "                   all        322       2335      0.896      0.806      0.891      0.539\n",
            "\n",
            "15 epochs completed in 1.354 hours.\n",
            "Optimizer stripped from task_icvr/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from task_icvr/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating task_icvr/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:11<00:00,  1.03s/it]\n",
            "                   all        322       2335      0.893      0.806      0.891      0.539\n",
            "                 human        322        825      0.788       0.63      0.798      0.437\n",
            "                helmet        322        678       0.94      0.839      0.893      0.473\n",
            "                jacket        322        832      0.951      0.948      0.981      0.708\n",
            "Results saved to \u001b[1mtask_icvr/exp\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 442... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▂▄▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▁▃▄▅▆▇▆▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▃▄▆▆▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▄▅▇▇███████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▅▄▄▃▃▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▅▄▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss █▄▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▇▅▄▄▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▇▅▄▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▅▅▅▄▃▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 █▅▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▃▆█▇▇▇▆▅▅▄▄▃▂▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 ▃▆█▇▇▇▆▅▅▄▄▃▂▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             best/epoch 14\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/mAP_0.5 0.89123\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      best/mAP_0.5:0.95 0.53948\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/precision 0.89597\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            best/recall 0.80584\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.89069\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.53904\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.89301\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.80595\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.04438\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.01308\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.01646\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.04184\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.01295\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.01724\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00142\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00142\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.00142\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 497 media file(s), 15 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mserene-snowball-1\u001b[0m: \u001b[34mhttps://wandb.ai/_bro/task_icvr/runs/28hzbycr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20221014_140835-28hzbycr/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train YOLOv3"
      ],
      "metadata": {
        "id": "nyZUKo6Vc5lW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/ultralytics/yolov3.git\n",
        "%cd /content/yolov3\n",
        "!pip install -r requirements.txt\n",
        "!pip install \"wandb==0.12.10\""
      ],
      "metadata": {
        "id": "p8gqBPbXIRAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "  --data ../data.yaml \\\n",
        "  --epochs 15 \\\n",
        "  --project task_icvr \\\n",
        "  --bbox_interval 1 \\\n",
        "  --save-period 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGNLTHwtCPCv",
        "outputId": "42ff8f97-7076-4471-8aca-39ac3dc88be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m_bro\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov3.pt, cfg=, data=../data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=15, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=task_icvr, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.6.0-24-gb0b071d torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir task_icvr', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.4 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msweet-deluge-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/_bro/task_icvr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/_bro/task_icvr/runs/27se4qln\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolov3/wandb/run-20221014_153858-27se4qln\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.6.0/yolov3.pt to yolov3.pt...\n",
            "100% 119M/119M [00:00<00:00, 137MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1     43080  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61534504 parameters, 61534504 gradients, 155.3 GFLOPs\n",
            "\n",
            "Transferred 433/439 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 72 weight, 75 weight (no decay), 75 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train/labels' images and labels...2578 found, 0 missing, 121 empty, 0 corrupted: 100% 2578/2578 [00:01<00:00, 2031.75it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../valid/labels' images and labels...322 found, 0 missing, 16 empty, 0 corrupted: 100% 322/322 [00:00<00:00, 943.34it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../valid/labels.cache\n",
            "Plotting labels to task_icvr/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.08 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mtask_icvr/exp\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/14     11.9G   0.08796   0.03473   0.02499        27       640: 100% 162/162 [05:44<00:00,  2.12s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:15<00:00,  1.42s/it]\n",
            "                 all        322       2335      0.197       0.56      0.224     0.0402\n",
            "Saving model artifact on epoch 1\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/14     12.7G   0.07142   0.02184   0.01873        33       640: 100% 162/162 [05:35<00:00,  2.07s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:15<00:00,  1.39s/it]\n",
            "                 all        322       2335      0.457      0.723      0.545      0.157\n",
            "Saving model artifact on epoch 2\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/14     12.7G   0.06324   0.02009   0.01698        23       640: 100% 162/162 [05:42<00:00,  2.12s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:15<00:00,  1.39s/it]\n",
            "                 all        322       2335      0.857      0.768      0.839      0.374\n",
            "Saving model artifact on epoch 3\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/14     12.7G   0.06348   0.01904   0.01561        19       640: 100% 162/162 [05:43<00:00,  2.12s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:14<00:00,  1.35s/it]\n",
            "                 all        322       2335      0.884      0.836      0.894      0.457\n",
            "Saving model artifact on epoch 4\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/14     12.7G   0.05835   0.01854   0.01526        16       640: 100% 162/162 [05:39<00:00,  2.10s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:16<00:00,  1.46s/it]\n",
            "                 all        322       2335      0.907      0.855      0.919      0.527\n",
            "Saving model artifact on epoch 5\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/14     12.7G   0.05675   0.01791   0.01479        18       640: 100% 162/162 [05:37<00:00,  2.08s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:14<00:00,  1.36s/it]\n",
            "                 all        322       2335      0.932      0.842      0.913      0.475\n",
            "Saving model artifact on epoch 6\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/14     12.7G   0.05303   0.01754   0.01396        16       640: 100% 162/162 [05:37<00:00,  2.08s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:16<00:00,  1.47s/it]\n",
            "                 all        322       2335      0.923      0.877       0.93      0.549\n",
            "Saving model artifact on epoch 7\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/14     12.7G    0.0513   0.01669   0.01394        49       640: 100% 162/162 [05:38<00:00,  2.09s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:16<00:00,  1.46s/it]\n",
            "                 all        322       2335      0.926      0.876       0.93      0.522\n",
            "Saving model artifact on epoch 8\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/14     12.7G    0.0481   0.01663   0.01358         5       640: 100% 162/162 [05:36<00:00,  2.08s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:15<00:00,  1.40s/it]\n",
            "                 all        322       2335      0.921      0.891      0.939      0.576\n",
            "Saving model artifact on epoch 9\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/14     12.7G   0.04589   0.01585   0.01305        15       640: 100% 162/162 [05:34<00:00,  2.07s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:15<00:00,  1.45s/it]\n",
            "                 all        322       2335       0.94      0.887      0.944      0.584\n",
            "Saving model artifact on epoch 10\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/14     12.7G   0.04468   0.01561   0.01304        33       640: 100% 162/162 [05:36<00:00,  2.07s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:15<00:00,  1.39s/it]\n",
            "                 all        322       2335      0.936       0.89      0.945      0.604\n",
            "Saving model artifact on epoch 11\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/14     12.7G    0.0433    0.0153   0.01278        16       640: 100% 162/162 [05:36<00:00,  2.08s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:14<00:00,  1.33s/it]\n",
            "                 all        322       2335      0.951      0.895       0.95       0.62\n",
            "Saving model artifact on epoch 12\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/14     12.7G   0.04228   0.01526   0.01255        33       640: 100% 162/162 [05:32<00:00,  2.05s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:17<00:00,  1.61s/it]\n",
            "                 all        322       2335      0.939        0.9      0.948      0.624\n",
            "Saving model artifact on epoch 13\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/14     12.7G   0.04144   0.01496   0.01229        38       640: 100% 162/162 [05:33<00:00,  2.06s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:18<00:00,  1.67s/it]\n",
            "                 all        322       2335      0.935      0.905      0.951      0.628\n",
            "Saving model artifact on epoch 14\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/14     12.7G   0.04067   0.01513   0.01242        33       640: 100% 162/162 [05:36<00:00,  2.07s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:16<00:00,  1.49s/it]\n",
            "                 all        322       2335      0.949      0.888      0.949      0.635\n",
            "\n",
            "15 epochs completed in 1.517 hours.\n",
            "Optimizer stripped from task_icvr/exp/weights/last.pt, 123.5MB\n",
            "Optimizer stripped from task_icvr/exp/weights/best.pt, 123.5MB\n",
            "\n",
            "Validating task_icvr/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 261 layers, 61508200 parameters, 0 gradients, 154.6 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 11/11 [00:11<00:00,  1.07s/it]\n",
            "                 all        322       2335      0.949      0.888      0.949      0.634\n",
            "               human        322        825      0.959      0.795      0.923      0.598\n",
            "              helmet        322        678      0.953      0.903      0.943      0.563\n",
            "              jacket        322        832      0.935      0.966      0.981      0.742\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 2124... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▄▇▇███████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▂▅▆▇▆▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▃▇▇███████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▄▅▇▇▇▇▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▆▄▄▄▃▃▃▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▅▄▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss █▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▅▅▄▃▃▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▆▅▄▃▃▃▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▆▄▄▃▃▃▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▃▅▆▇█▇▇▆▅▄▃▂▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▃▅▆▇█▇▇▆▅▄▃▂▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▇▆▄▃▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.9493\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.63456\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.94872\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.88828\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.04067\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.01242\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.01513\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.03891\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.01204\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.01628\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00139\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00139\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.00139\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 497 media file(s), 15 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msweet-deluge-2\u001b[0m: \u001b[34mhttps://wandb.ai/_bro/task_icvr/runs/27se4qln\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20221014_153858-27se4qln/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "Results saved to \u001b[1mtask_icvr/exp\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}